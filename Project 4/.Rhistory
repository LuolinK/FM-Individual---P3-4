plot(simulatedPrices[,1], type="l", col="blue", ylim=c(min(simulatedPrices),max(simulatedPrices)), xlab="Days", ylab="Bitcoin Price")
for (i in 2:trials) {
lines(simulatedPrices[,i], col=colors[i])
}
# Cryptocurrency 4 - ETH
library(quantmod)
# Define parameters for the simulation
days <- 365
trials <- 1000
lastPrice <- tail(ETH$Close, n=1)
# Run the Monte Carlo simulation
simulatedPrices <- matrix(nrow=days, ncol=trials)
for (i in 1:trials) {
simulatedReturns <- rnorm(days, mean=mean(eth_return), sd=sd(eth_return))
simulatedPrices[,i] <- cumprod(1+simulatedReturns)*lastPrice
}
# Plot the results
colors <- rainbow(trials) # Generate a sequence of colors
plot(simulatedPrices[,1], type="l", col="blue", ylim=c(min(simulatedPrices),max(simulatedPrices)), xlab="Days", ylab=" Ethereum Price")
for (i in 2:trials) {
lines(simulatedPrices[,i], col=colors[i])
}
# Cryptocurrency 5 - XRP
library(quantmod)
# Define parameters for the simulation
days <- 365
trials <- 1000
lastPrice <- tail(XRP$Close, n=1)
# Run the Monte Carlo simulation
simulatedPrices <- matrix(nrow=days, ncol=trials)
for (i in 1:trials) {
simulatedReturns <- rnorm(days, mean=mean(xrp_return), sd=sd(xrp_return))
simulatedPrices[,i] <- cumprod(1+simulatedReturns)*lastPrice
}
# Plot the results
colors <- rainbow(trials) # Generate a sequence of colors
plot(simulatedPrices[,1], type="l", col="blue", ylim=c(min(simulatedPrices),max(simulatedPrices)), xlab="Days", ylab=" XRP Price")
for (i in 2:trials) {
lines(simulatedPrices[,i], col=colors[i])
}
setwd("~/Downloads/Financial Modelling/Chapter 3")
setwd("~/Downloads/Financial Modelling/Project 3")
library (xts)
library (zoo)
library (PerformanceAnalytics)
require (sandwich)
require(lmtest)
## read the file to load the data
close.prices = read.csv("Hourly_CryptoCompare_Index_BTC_USDT.csv", header = TRUE) #importing the data
close.prices$Index = as.POSIXct(close.prices$Index,format="%d/%m/%Y %H", tz = "") # converting the first column into date format
close.prices.xts <- xts(close.prices[,-1], order.by=close.prices[,1]) # convert the object into xts object (time series object)
close.prices.zoo  <- as.zoo(close.prices.xts) # convert the time series object into zoo object
head(close.prices)
return = Return.calculate( close.prices.xts , method = "log") # automatically calculate return
library(pastecs)
install.packages("pastecs")
library (xts)
library (zoo)
library (xts)
library (PerformanceAnalytics)
library (PerformanceAnalytics)
require (sandwich)
require (sandwich)
require(lmtest)
require(lmtest)
## read the file to load the data
close.prices = read.csv("Hourly_CryptoCompare_Index_BTC_USDT.csv", header = TRUE) #importing the data
close.prices$Index = as.POSIXct(close.prices$Index,format="%d/%m/%Y %H", tz = "") # converting the first column into date format
close.prices.xts <- xts(close.prices[,-1], order.by=close.prices[,1]) # convert the object into xts object (time series object)
close.prices.zoo  <- as.zoo(close.prices.xts) # convert the time series object into zoo object
head(close.prices)
return = Return.calculate( close.prices.xts , method = "log") # automatically calculate return
library(pastecs)
library(pastecs)
descriptive.stat.return = stat.desc(return) # descriptive statistics
# a function to create CSAD and Rm
exchange.herd = function(return)
{
n=ncol(return)
Rm = rowMeans(return)
temp_dif =abs(return-Rm)
temp_sum = rowSums(temp_dif)
CSAD = temp_sum / ncol(return)
CSAD = cbind (CSAD, Rm)
return (CSAD)
}
f = exchange.herd(return) # calling the function "exchange.herd" that calculates CSAD and Rm
library (xts)
library (zoo)
library (PerformanceAnalytics)
require (sandwich)
require(lmtest)
## read the file to load the data
close.prices = read.csv("Hourly_CryptoCompare_Index_BTC_USDT.csv", header = TRUE) #importing the data
close.prices$Index = as.POSIXct(close.prices$Index,format="%d/%m/%Y %H", tz = "") # converting the first column into date format
close.prices.xts <- xts(close.prices[,-1], order.by=close.prices[,1]) # convert the object into xts object (time series object)
close.prices.zoo  <- as.zoo(close.prices.xts) # convert the time series object into zoo object
head(close.prices)
return = Return.calculate( close.prices.xts , method = "log") # automatically calculate return
library(pastecs)
descriptive.stat.return = stat.desc(return) # descriptive statistics
# a function to create CSAD and Rm
exchange.herd = function(return)
{
n=ncol(return)
Rm = rowMeans(return)
temp_dif =abs(return-Rm)
temp_sum = rowSums(temp_dif)
CSAD = temp_sum / ncol(return)
CSAD = cbind (CSAD, Rm)
return (CSAD)
}
f = exchange.herd(return) # calling the function "exchange.herd" that calculates CSAD and Rm
head (f) # show the first 6 rows
CSAD.df = fortify.zoo(f) # converting f into a dataframe (to simplify further calculations)
head(CSAD.df)
CSAD.df = fortify.zoo(f) # converting f into a dataframe (to simplify further calculations)
CSAD.df$Rm2 = CSAD.df$Rm^2 # calculating Rm^2
CSAD.df = CSAD.df[-c(1),] # removing the first row with NAs
# Create interaction terms
CSAD.df$DupRm = CSAD.df$Dup * abs(CSAD.df$Rm)
CSAD.df$DupRm2 = CSAD.df$Dup * CSAD.df$Rm2
# Create a dummy variable for up days
CSAD.df$Dup = ifelse(CSAD.df$Rm > 0, 1, 0)
# Create interaction terms
CSAD.df$DupRm = CSAD.df$Dup * abs(CSAD.df$Rm)
CSAD.df$DupRm2 = CSAD.df$Dup * CSAD.df$Rm2
CSAD.df$DownRm = (1 - CSAD.df$Dup) * CSAD.df$Rm
CSAD.df$DownRm2 = (1 - CSAD.df$Dup) * CSAD.df$Rm2
# Estimate the model
model = lm(CSAD ~ DupRm + DownRm + DupRm2 + DownRm2, data = CSAD.df)
y = CSAD.df$CSAD
x1 = CSAD.df$DupRm
x2 = CSAD.df$DownRm
x3 = CSAD.df$DupRm2
x4 = CSAD.df$DownRm2
#Linear model
linearMod <- lm(y~x1+x2+x3=x4)  # build linear regression model on full data
#Linear model
linearMod <- lm(y~x1+x2+x3+x4)  # build linear regression model on full data
print(linearMod)
summary(linearMod)
# estimate TV Linear Regression
require (tvReg)
tvlm.fit = tvLM(y~x1+x2, bw = NULL  ) #bw=0.68
# estimate TV Linear Regression
require (tvReg)
tvlm.fit = tvLM(y~x1+x2, bw = NULL  ) #bw=0.68
head (tvlm.fit$coefficients)
tvlm.fit = tvLM(y~x1+x2+x3+x4, bw = NULL  ) #bw=0.188
plot(tvlm.fit$coefficients[,1], type="l")
plot(tvlm.fit$coefficients[,2], type="l")
plot(tvlm.fit$coefficients[,3], type="l")
plot(tvlm.fit$coefficients[,4], type="l")
#Linear model
linearMod <- lm(y~x1+x2+x3+x4)  # build linear regression model on full data
print(linearMod)
summary(linearMod)
# Estimate the model
model = lm(CSAD ~ DupRm + DownRm + DupRm2 + DownRm2, data = CSAD.df)
library(ggplot2)
# Extract the coefficient estimates and standard errors
coefficients <- coef(model)[-1]  # Exclude the intercept
se <- summary(model)$coefficients[-1, "Std. Error"]  # Exclude the intercept
# Create a data frame for plotting
result_df <- data.frame(Coefficient = names(coefficients),
Estimate = coefficients,
SE = se)
# Plot the coefficients with error bars
ggplot(result_df, aes(x = Coefficient, y = Estimate, ymin = Estimate - 1.96 * SE, ymax = Estimate + 1.96 * SE)) +
geom_point() +
geom_errorbar(width = 0.2) +
coord_flip() +
labs(x = "Coefficient", y = "Estimate") +
ggtitle("Herding in Finance: Coefficient Estimates") +
theme_minimal()
library (xts)
library (zoo)
library (PerformanceAnalytics)
require (sandwich)
require(lmtest)
## read the file to load the data
close.prices = read.csv("Hourly_CryptoCompare_Index_BTC_USDT.csv", header = TRUE) #importing the data
close.prices$Index = as.POSIXct(close.prices$Index,format="%d/%m/%Y %H", tz = "") # converting the first column into date format
close.prices.xts <- xts(close.prices[,-1], order.by=close.prices[,1]) # convert the object into xts object (time series object)
close.prices.zoo  <- as.zoo(close.prices.xts) # convert the time series object into zoo object
head(close.prices)
return = Return.calculate( close.prices.xts , method = "log") # automatically calculate return
library(pastecs)
descriptive.stat.return = stat.desc(return) # descriptive statistics
# a function to create CSAD and Rm
exchange.herd = function(return)
{
n=ncol(return)
Rm = rowMeans(return)
temp_dif =abs(return-Rm)
temp_sum = rowSums(temp_dif)
CSAD = temp_sum / ncol(return)
CSAD = cbind (CSAD, Rm)
return (CSAD)
}
f = exchange.herd(return) # calling the function "exchange.herd" that calculates CSAD and Rm
head (f) # show the first 6 rows
CSAD.df = fortify.zoo(f) # converting f into a dataframe (to simplify further calculations)
CSAD.df$Rm2 = CSAD.df$Rm^2 # calculating Rm^2
CSAD.df = CSAD.df[-c(1),] # removing the first row with NAs
head (CSAD.df) # show the first 6 rows
tail (CSAD.df) # show the last 6 rows
# Create a dummy variable for up days
CSAD.df$Dup = ifelse(CSAD.df$Rm > 0, 1, 0)
# Create interaction terms
CSAD.df$DupRm = CSAD.df$Dup * abs(CSAD.df$Rm)
CSAD.df$DupRm2 = CSAD.df$Dup * CSAD.df$Rm2
CSAD.df$DownRm = (1 - CSAD.df$Dup) * CSAD.df$Rm
CSAD.df$DownRm2 = (1 - CSAD.df$Dup) * CSAD.df$Rm2
# Estimate the model
model = lm(CSAD ~ DupRm + DownRm + DupRm2 + DownRm2, data = CSAD.df)
library(ggplot2)
# Extract the coefficient estimates and standard errors
coefficients <- coef(model)[-1]  # Exclude the intercept
se <- summary(model)$coefficients[-1, "Std. Error"]  # Exclude the intercept
# Create a data frame for plotting
result_df <- data.frame(Coefficient = names(coefficients),
Estimate = coefficients,
SE = se)
# Plot the coefficients with error bars
ggplot(result_df, aes(x = Coefficient, y = Estimate, ymin = Estimate - 1.96 * SE, ymax = Estimate + 1.96 * SE)) +
geom_point() +
geom_errorbar(width = 0.2) +
coord_flip() +
labs(x = "Coefficient", y = "Estimate") +
ggtitle("Herding in Finance: Coefficient Estimates") +
theme_minimal()
y = CSAD.df$CSAD
x1 = CSAD.df$DupRm
x2 = CSAD.df$DownRm
x3 = CSAD.df$DupRm2
x4 = CSAD.df$DownRm2
#Linear model
linearMod <- lm(y~x1+x2+x3+x4)  # build linear regression model on full data
print(linearMod)
summary(linearMod)
#Newey-West Heteroscedasticity and Autocorrelation consistent (HAC) estimators
coeftest(linearMod,vcov=NeweyWest(linearMod,verbose=T))
tvlm.fit = tvLM(y~x1+x2+x3+x4, bw = NULL  ) #bw=20
head (tvlm.fit$coefficients)
plot(tvlm.fit$coefficients[,1], type="l")
plot(tvlm.fit$coefficients[,2], type="l")
plot(tvlm.fit$coefficients[,3], type="l")
plot(tvlm.fit$coefficients[,4], type="l")
# Bayesian models
library (brms)
# Bayesian models
library (brms)
hourly = cbind(y, x1, x2, x3, x4)
model = brm(formula = y ~ x1+x2+x3+x4,
data    = hourly,
seed    = 123)
model = brm(formula = y ~ x1+x2+x3+x4,
data    = hourly,
seed    = 123)
model = brm(formula = y ~ x1+x2+x3+x4,
data    = hourly,
seed    = 123)
summary(model)
require (xts) # attache the package to convert our dataframes into an xts (time-series) object for simplicity in calculations
require(zoo)
library(tidyquant)
require (xts) # attache the package to convert our dataframes into an xts (time-series) object for simplicity in calculations
require(zoo)
library(tidyquant)
# import a time series of different frequency
# Stock 1 - Apple
AAPL = read.csv("AAPL.csv")
AAPL$Date = as.Date(AAPL$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
AAPL.xts = xts(AAPL['Close'], order.by=AAPL$Date)  # converting a data frame into xts onject (time-series object)
head(AAPL.xts)
aapl_return = diff (log(AAPL.xts)) # Log return calculation
aapl_return = aapl_return [-1] # removing the first empty observation, received after return calculation
head(aapl_return)
# Stock 2 - Amazon
AMZN = read.csv("AMZN.csv")
AMZN$Date = as.Date(AMZN$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
AMZN.xts = xts(AMZN['Close'], order.by=AMZN$Date)  # converting a data frame into xts onject (time-series object)
head(AMZN.xts)
amzn_return = diff (log(AMZN.xts)) # Log return calculation
amzn_return = amzn_return [-1] # removing the first empty observation, received after return calculation
# Stock 3 - Google
GOOG = read.csv("GOOG.csv")
GOOG$Date = as.Date(GOOG$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
GOOG.xts = xts(GOOG['Close'], order.by=GOOG$Date)  # converting a data frame into xts onject (time-series object)
head(GOOG.xts)
goog_return = diff (log(GOOG.xts)) # Log return calculation
goog_return = goog_return [-1] # removing the first empty observation, received after return calculation
# Stock 4 - Microsoft
MSFT = read.csv("MSFT.csv")
MSFT$Date = as.Date(MSFT$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
MSFT.xts = xts(MSFT['Close'], order.by=MSFT$Date)  # converting a data frame into xts onject (time-series object)
head(MSFT.xts)
msft_return = diff (log(MSFT.xts)) # Log return calculation
msft_return = msft_return [-1] # removing the first empty observation, received after return calculation
# Stock 5 - Tesla
TSLA = read.csv("TSLA.csv")
TSLA$Date = as.Date(TSLA$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
TSLA.xts = xts(TSLA['Close'], order.by=TSLA$Date)  # converting a data frame into xts onject (time-series object)
head(TSLA.xts)
tsla_return = diff (log(TSLA.xts)) # Log return calculation
tsla_return = tsla_return [-1] # removing the first empty observation, received after return calculation
# Cypto 1 – Cardano
ADA = read.csv("ADA-USD.csv")
ADA$Date = as.Date(ADA$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
ADA.xts = xts(ADA['Close'], order.by=ADA$Date)  # converting a data frame into xts onject (time-series object)
head(ADA.xts)
ada_return = diff (log(ADA.xts)) # Log return calculation
ada_return = ada_return [-1] # removing the first empty observation, received after return calculation
# Cypto 2 – BNB USD
BNB = read.csv("BNB-USD.csv")
BNB$Date = as.Date(BNB$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
BNB.xts = xts(BNB['Close'], order.by=BNB$Date)  # converting a data frame into xts onject (time-series object)
head(BNB.xts)
bnb_return = diff (log(BNB.xts)) # Log return calculation
bnb_return = bnb_return [-1] # removing the first empty observation, received after return calculation
# Cypto 3 – Bitcoin
BTC = read.csv("BTC-USD.csv")
BTC$Date = as.Date(BTC$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
BTC.xts = xts(BTC['Close'], order.by=BTC$Date)  # converting a data frame into xts onject (time-series object)
head(BTC.xts)
btc_return = diff (log(BTC.xts)) # Log return calculation
btc_return = btc_return [-1] # removing the first empty observation, received after return calculation
# Cypto 4 – Ethereum
ETH = read.csv("ETH-USD.csv")
ETH$Date = as.Date(ETH$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
ETH.xts = xts(ETH['Close'], order.by=ETH$Date)  # converting a data frame into xts onject (time-series object)
head(ETH.xts)
setwd("~/Downloads/Financial Modelling/Project 4")
require (xts) # attache the package to convert our dataframes into an xts (time-series) object for simplicity in calculations
require(zoo)
library(tidyquant)
# import a time series of different frequency
# Stock 1 - Apple
AAPL = read.csv("AAPL.csv")
AAPL$Date = as.Date(AAPL$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
AAPL.xts = xts(AAPL['Close'], order.by=AAPL$Date)  # converting a data frame into xts onject (time-series object)
head(AAPL.xts)
aapl_return = diff (log(AAPL.xts)) # Log return calculation
aapl_return = aapl_return [-1] # removing the first empty observation, received after return calculation
head(aapl_return)
# Stock 2 - Amazon
AMZN = read.csv("AMZN.csv")
AMZN$Date = as.Date(AMZN$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
AMZN.xts = xts(AMZN['Close'], order.by=AMZN$Date)  # converting a data frame into xts onject (time-series object)
head(AMZN.xts)
amzn_return = diff (log(AMZN.xts)) # Log return calculation
amzn_return = amzn_return [-1] # removing the first empty observation, received after return calculation
# Stock 3 - Google
GOOG = read.csv("GOOG.csv")
GOOG$Date = as.Date(GOOG$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
GOOG.xts = xts(GOOG['Close'], order.by=GOOG$Date)  # converting a data frame into xts onject (time-series object)
head(GOOG.xts)
goog_return = diff (log(GOOG.xts)) # Log return calculation
goog_return = goog_return [-1] # removing the first empty observation, received after return calculation
# Stock 4 - Microsoft
MSFT = read.csv("MSFT.csv")
MSFT$Date = as.Date(MSFT$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
MSFT.xts = xts(MSFT['Close'], order.by=MSFT$Date)  # converting a data frame into xts onject (time-series object)
head(MSFT.xts)
msft_return = diff (log(MSFT.xts)) # Log return calculation
msft_return = msft_return [-1] # removing the first empty observation, received after return calculation
# Stock 5 - Tesla
TSLA = read.csv("TSLA.csv")
TSLA$Date = as.Date(TSLA$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
TSLA.xts = xts(TSLA['Close'], order.by=TSLA$Date)  # converting a data frame into xts onject (time-series object)
head(TSLA.xts)
tsla_return = diff (log(TSLA.xts)) # Log return calculation
tsla_return = tsla_return [-1] # removing the first empty observation, received after return calculation
# Cypto 1 – Cardano
ADA = read.csv("ADA-USD.csv")
ADA$Date = as.Date(ADA$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
ADA.xts = xts(ADA['Close'], order.by=ADA$Date)  # converting a data frame into xts onject (time-series object)
head(ADA.xts)
ada_return = diff (log(ADA.xts)) # Log return calculation
ada_return = ada_return [-1] # removing the first empty observation, received after return calculation
# Cypto 2 – BNB USD
BNB = read.csv("BNB-USD.csv")
BNB$Date = as.Date(BNB$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
BNB.xts = xts(BNB['Close'], order.by=BNB$Date)  # converting a data frame into xts onject (time-series object)
head(BNB.xts)
bnb_return = diff (log(BNB.xts)) # Log return calculation
bnb_return = bnb_return [-1] # removing the first empty observation, received after return calculation
# Cypto 3 – Bitcoin
BTC = read.csv("BTC-USD.csv")
BTC$Date = as.Date(BTC$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
BTC.xts = xts(BTC['Close'], order.by=BTC$Date)  # converting a data frame into xts onject (time-series object)
head(BTC.xts)
btc_return = diff (log(BTC.xts)) # Log return calculation
btc_return = btc_return [-1] # removing the first empty observation, received after return calculation
# Cypto 4 – Ethereum
ETH = read.csv("ETH-USD.csv")
ETH$Date = as.Date(ETH$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
ETH.xts = xts(ETH['Close'], order.by=ETH$Date)  # converting a data frame into xts onject (time-series object)
head(ETH.xts)
eth_return = diff (log(ETH.xts)) # Log return calculation
eth_return = eth_return [-1] # removing the first empty observation, received after return calculation
# Cypto 5 – XRP
XRP = read.csv("XRP-USD.csv")
XRP$Date = as.Date(XRP$Date,format="%Y-%m-%d", tz = "")# converting a date column into date format
XRP.xts = xts(XRP['Close'], order.by=XRP$Date)  # converting a data frame into xts onject (time-series object)
head(XRP.xts)
xrp_return = diff (log(XRP.xts)) # Log return calculation
xrp_return = xrp_return [-1] # removing the first empty observation, received after return calculation
# Combine assets into a matrix
assets <- cbind(aapl_return$Close, amzn_return$Close, goog_return$Close,
msft_return$Close, tsla_return$Close, ada_return$Close,
bnb_return$Close, btc_return$Close, eth_return$Close,
xrp_return$Close)
merged_data <- merge(AAPL.xts, AMZN.xts, GOOG.xts, MSFT.xts, TSLA.xts, ADA.xts,
BNB.xts, BTC.xts, ETH.xts, XRP.xts, all=FALSE)
head(merged_data)
# Calculate correlation matrix
correlation_matrix <- cor(merged_data)
colnames(correlation_matrix) <- c("Apple","Amazon","Google","Microsoft","Tesla",
"Cardano","BNB","Bitcoin","Ethereum","XRP")
rownames(correlation_matrix) <-c("Apple","Amazon","Google","Microsoft","Tesla",
"Cardano","BNB","Bitcoin","Ethereum","XRP")
# Print correlation matrix
print(correlation_matrix)
# Load the 'knitr' package
library(knitr)
# Convert the correlation matrix to a data frame
correlation_df <- as.data.frame(correlation_matrix)
# Print the table using the kable() function
kable(correlation_df, format = "markdown")
## Causality based on DAG
install.packages("pcalg")
library(pcalg)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("graph")
summary(dag)
# Plot the estimated DAG:
library(Rgraphviz)
# Plot the estimated DAG:
library(Rgraphviz)
plot(dag)
# Stock 1 - Apple:
## GARCH model
# Y return AAPL
Y = aapl_return$Close
library (tseries)
aapl.garch.1 <- garch(Y, order =c(1,1))
summary (aapl.garch.1)
library (rugarch)
aapl.garch.spec = ugarchspec(mean.model=list(armaOrder=c(0,0)), distribution="norm")
aapl.garch.2 = ugarchfit(aapl.garch.spec, Y)
summary(aapl.garch.2)
plot (aapl.garch.2)
# Factor Analysis
df = cbind(AAPL$Close, AMZN$Close,
GOOG$Close, MSFT$Close,
TSLA$Close,ADA$Close,
BNB$Close, BTC$Close,
ETH$Close, XRP$Close
)
colnames(df) <- c("Apple","Amazon","Google","Microsoft","Tesla",
"Cardano","BNB","Bitcoin","Ethereum","XRP")
head(df)
fa_none = factanal(df[,1:10],4,rotation="none") # 4 factor model without rotation
print(fa_none,cutoff=0.1) # By convention, any loading with an absolute value less than the parameter cutoff is not printed, and the default value of cutoff is 0.1
# VARIMAX rotation
fa_vari = factanal(df[,1:10],4,rotation="varimax") #factor model with rotation
print(fa_vari,cutoff=0.1,sort=T)
print(fa_vari,cutoff=0.1)
sum(fa_vari$loadings[,1]^2)
B=fa_vari$loadings[,] # factor loadings
library (psych) # the library for factor analysis
library (GPArotation) # to estimate oblimin rotation
assets = df[,1:10]
describe(df) # general description of the data
##Assessing the Factorability of the Data
#Bartlett's Test of Sphericity
cortest.bartlett(df)
#KMO
KMO(df)
##Determining the Number of Factors to Extract
# scree plot
scree(df)
#Parallel Analysis
fa.parallel (df) #
# estimation factor model
factor.model <- fa(df, nfactors = 3, fm="ols", max.iter = 100, rotate = "oblimin")
# make it visual
fa.diagram(factor.model) #
# Communality
factor.model$communality
#Eeigenvalues
factor.model$e.values
#Percentage of Variance Accounted For
100*factor.model$e.values/length(factor.model$e.values)
print(factor.model$loadings, cutoff=0, digits=3)
print(factor.model$Structure, cutoff=0, digits=3)
# estimation factor model
factor.model <- fa(df, nfactors = 2, fm="ols", max.iter = 100, rotate = "oblimin")
# make it visual
fa.diagram(factor.model) #
# Communality
factor.model$communality
#Eeigenvalues
factor.model$e.values
#Percentage of Variance Accounted For
100*factor.model$e.values/length(factor.model$e.values)
print(factor.model$loadings, cutoff=0, digits=3)
print(factor.model$Structure, cutoff=0, digits=3)
